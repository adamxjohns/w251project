{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection for the 5 Celebrity Faces Dataset\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "from numpy import savez_compressed\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "# from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.contrib.tensorrt as trt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# from tf_trt_models.detection import download_detection_model, build_detection_graph\n",
    "\n",
    "FROZEN_GRAPH_NAME = 'data/frozen_inference_graph_face.pb'\n",
    "\n",
    "output_dir=''\n",
    "frozen_graph = tf.compat.v1.GraphDef()\n",
    "with open(os.path.join(output_dir, FROZEN_GRAPH_NAME), 'rb') as f:\n",
    "  frozen_graph.ParseFromString(f.read())\n",
    "\n",
    "INPUT_NAME='image_tensor'\n",
    "BOXES_NAME='detection_boxes'\n",
    "CLASSES_NAME='detection_classes'\n",
    "SCORES_NAME='detection_scores'\n",
    "MASKS_NAME='detection_masks'\n",
    "NUM_DETECTIONS_NAME='num_detections'\n",
    "\n",
    "input_names = [INPUT_NAME]\n",
    "output_names = [BOXES_NAME, CLASSES_NAME, SCORES_NAME, NUM_DETECTIONS_NAME]\n",
    "\n",
    "\n",
    "# trt_graph = trt.create_inference_graph(\n",
    "#     input_graph_def=frozen_graph,\n",
    "#     outputs=output_names,\n",
    "#     max_batch_size=1,\n",
    "#     max_workspace_size_bytes=1 << 25,\n",
    "#     precision_mode='FP16',\n",
    "#     minimum_segment_size=50\n",
    "# )\n",
    "\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.compat.v1.Session(config=tf_config)\n",
    "\n",
    "# use this if you want to try on the optimized TensorRT graph\n",
    "# Note that this will take a while\n",
    "# tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "# use this if you want to try directly on the frozen TF graph\n",
    "# this is much faster\n",
    "tf.import_graph_def(frozen_graph, name='')\n",
    "\n",
    "tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\n",
    "tf_scores = tf_sess.graph.get_tensor_by_name('detection_scores:0')\n",
    "tf_boxes = tf_sess.graph.get_tensor_by_name('detection_boxes:0')\n",
    "tf_classes = tf_sess.graph.get_tensor_by_name('detection_classes:0')\n",
    "tf_num_detections = tf_sess.graph.get_tensor_by_name('num_detections:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    image = cv2.imread(filename)\n",
    "    \n",
    "    if type(image) == type(None):\n",
    "        return None\n",
    "    \n",
    "    if image.shape[2] <= 2:\n",
    "        return None\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(image, (300, 300))\n",
    "    scores, boxes, classes, num_detections = tf_sess.run([tf_scores, tf_boxes, tf_classes, tf_num_detections], feed_dict={\n",
    "        tf_input: image_resized[None, ...]\n",
    "    })\n",
    "\n",
    "    boxes = boxes[0] # in\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "    num_detections = num_detections[0]\n",
    "\n",
    "    plot_ind = 0\n",
    "    DETECTION_THRESHOLD = 0.01\n",
    "    images = []\n",
    "    for i in range(int(num_detections)):\n",
    "        if scores[i] < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "        # scale box to image coordinates\n",
    "        box = boxes[i] * np.array([image.shape[0], image.shape[1], image.shape[0], image.shape[1]])\n",
    "    #     print(box)\n",
    "        box = box.astype(int)\n",
    "        face = image[box[0]:box[2]+1, box[1]:box[3]+1]\n",
    "        image = Image.fromarray(face)\n",
    "        image = image.resize(required_size)\n",
    "#         images.append(image)\n",
    "        return image\n",
    "    \n",
    "# specify folder to plot\n",
    "# print(os.getcwd())\n",
    "# folder = 'data/train/elton_john/'\n",
    "# i = 1\n",
    "# # enumerate files\n",
    "# for filename in listdir(folder):\n",
    "# \t# path\n",
    "# #     print(filename)\n",
    "# \tpath = folder + filename\n",
    "# # \t# get face\n",
    "# \tface = extract_face(path)\n",
    "# \tprint(i, face.shape)\n",
    "# # \t# plot\n",
    "# \tpyplot.subplot(2, 7, i)\n",
    "# \tpyplot.axis('off')\n",
    "# \tpyplot.imshow(face)\n",
    "# \ti += 1\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded 14 examples for class: ben_afflek\n",
      ">loaded 22 examples for class: mindy_kaling\n",
      ">loaded 19 examples for class: madonna\n",
      ">loaded 21 examples for class: jerry_seinfeld\n",
      ">loaded 17 examples for class: elton_john\n",
      ">loaded 87 examples for class: unknown\n",
      "(180, 160, 160, 3) (180,)\n",
      ">loaded 5 examples for class: ben_afflek\n",
      ">loaded 5 examples for class: mindy_kaling\n",
      ">loaded 5 examples for class: madonna\n",
      ">loaded 5 examples for class: jerry_seinfeld\n",
      ">loaded 5 examples for class: elton_john\n",
      ">loaded 80 examples for class: unknown\n"
     ]
    }
   ],
   "source": [
    "def load_faces(directory):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in listdir(directory):\n",
    "        # path\n",
    "        path = directory + filename\n",
    "        # get face\n",
    "        face = extract_face(path)\n",
    "        if not face:\n",
    "            continue\n",
    "        # store\n",
    "        face_array = asarray(face)\n",
    "        faces.append(face_array)\n",
    "    return faces\n",
    "\n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "\tX, y = list(), list()\n",
    "\t# enumerate folders, on per class\n",
    "\tfor subdir in listdir(directory):\n",
    "\t\t# path\n",
    "\t\tpath = directory + subdir + '/'\n",
    "\t\t# skip any files that might be in the dir\n",
    "\t\tif not isdir(path):\n",
    "\t\t\tcontinue\n",
    "\t\t# load all faces in the subdirectory\n",
    "\t\tfaces = load_faces(path)\n",
    "\t\t# create labels\n",
    "\t\tlabels = [subdir for _ in range(len(faces))]\n",
    "\t\t# summarize progress\n",
    "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "\t\t# store\n",
    "\t\tX.extend(faces)\n",
    "\t\ty.extend(labels)\n",
    "\treturn asarray(X), asarray(y)\n",
    "\n",
    "# load train dataset\n",
    "trainX, trainy = load_dataset('data/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('data/val/')\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1:0' shape=(None, 160, 160, 3) dtype=float32>]\n",
      "[<tf.Tensor 'Bottleneck_BatchNorm/cond/Identity:0' shape=(None, 128) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example of loading the keras facenet model\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "face_net_model = load_model('facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print(face_net_model.inputs)\n",
    "print(face_net_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a face embedding for each face in the dataset using facenet\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "from keras.models import load_model\n",
    "\n",
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "\t# scale pixel values\n",
    "\tface_pixels = face_pixels.astype('float32')\n",
    "\t# standardize pixel values across channels (global)\n",
    "\tmean, std = face_pixels.mean(), face_pixels.std()\n",
    "\tface_pixels = (face_pixels - mean) / std\n",
    "\t# transform face into one sample\n",
    "\tsamples = expand_dims(face_pixels, axis=0)\n",
    "\t# make prediction to get embedding\n",
    "\tyhat = model.predict(samples)\n",
    "\treturn yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (180, 160, 160, 3) (180,) (105, 160, 160, 3) (105,)\n",
      "Loaded Model\n",
      "(180, 128)\n",
      "(105, 128)\n"
     ]
    }
   ],
   "source": [
    "# get embedding for train and test dataset\n",
    "\n",
    "# load the face dataset\n",
    "data = load('5-celebrity-faces-dataset.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "# load the facenet model\n",
    "# model = load_model('facenet_keras.h5')\n",
    "print('Loaded Model')\n",
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "\tembedding = get_embedding(face_net_model, face_pixels)\n",
    "\tnewTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "\tembedding = get_embedding(face_net_model, face_pixels)\n",
    "\tnewTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed('5-celebrity-faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# develop a classifier for the 5 Celebrity Faces Dataset\n",
    "from random import choice\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "# load faces\n",
    "data = load('5-celebrity-faces-dataset.npz')\n",
    "testX_faces = data['arr_2']\n",
    "# load face embeddings\n",
    "data = load('5-celebrity-faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "# fit model\n",
    "classifier = SVC(probability=True, class_weight = \"balanced\")\n",
    "classifier.fit(trainX, trainy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model on a random example from the test dataset\n",
    "faces = load('5-celebrity-faces-dataset.npz')\n",
    "test_faces = faces['arr_2']\n",
    "testy = data['arr_3']\n",
    "# test_faces = faces['arr_0']\n",
    "# testy = data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 100 inferences\n",
      "Time taken : 15.850003957748413 seconds\n",
      "Average 6.30914668958894 images per second\n",
      "Accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "\n",
    "def test_model(inference_num, show_each_case=False):\n",
    "    start = time.time()\n",
    "    correct = 0\n",
    "    for i in range(inference_num):\n",
    "        selection = choice([i for i in range(test_faces.shape[0])])\n",
    "        random_face_pixels = test_faces[selection]\n",
    "        random_face_emb = get_embedding(face_net_model, random_face_pixels)\n",
    "        # random_face_emb = testX[selection]\n",
    "        random_face_class = testy[selection]\n",
    "    #     random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "        # prediction for the face\n",
    "        samples = expand_dims(random_face_emb, axis=0)\n",
    "        yhat_class = classifier.predict(samples)\n",
    "        yhat_prob = classifier.predict_proba(samples)\n",
    "        # get name\n",
    "        class_index = yhat_class[0]\n",
    "        class_probability = yhat_prob[0,class_index] * 100\n",
    "        predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "        \n",
    "        if show_each_case:\n",
    "            print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "            print('Expected: %s' % random_face_class)\n",
    "#             plot for fun\n",
    "            pyplot.imshow(random_face_pixels)\n",
    "            title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "            pyplot.title(title)\n",
    "            pyplot.show()\n",
    "        if predict_names[0] == random_face_class:\n",
    "            correct += 1\n",
    "\n",
    "    end = time.time()\n",
    "    seconds = end - start\n",
    "\n",
    "    print(f\"Made {inference_num} inferences\")\n",
    "    print(\"Time taken : {0} seconds\".format(seconds))\n",
    "    print(f\"Average {inference_num/seconds} images per second\")\n",
    "    print(f\"Accuracy = {correct*1.0/inference_num}\")\n",
    "\n",
    "test_model(100, show_each_case = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
